{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3692828b",
   "metadata": {},
   "source": [
    "# Making original large CSV files\n",
    "\n",
    "This is the notebook where I was able to get the **5 different CSV files** for each country.\n",
    "\n",
    "The CSV files include the following countries: **Australia, Canada, India, United Kingdom, and the United States**\n",
    "\n",
    "These files contain the **pageviews from 2023 - 2024** for each country's **top 10,000 viewed articles**.\n",
    "\n",
    "*This code was edited from the code provided in the Final Project folder from Google Drive*\n",
    "\n",
    "### Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3efe62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>project</th>\n",
       "      <th>page_id</th>\n",
       "      <th>article</th>\n",
       "      <th>qid</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>19980263</td>\n",
       "      <td>Margot_Robbie</td>\n",
       "      <td>Q1924847</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>28786805</td>\n",
       "      <td>Karl_Stefanovic</td>\n",
       "      <td>Q6372275</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>44059</td>\n",
       "      <td>Harrison_Ford</td>\n",
       "      <td>Q81328</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>46823</td>\n",
       "      <td>George_V</td>\n",
       "      <td>Q269412</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>52382</td>\n",
       "      <td>Watergate_scandal</td>\n",
       "      <td>Q42761</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    country country_code       project   page_id  \\\n",
       "0 2023-02-06  Australia           AU  en.wikipedia  19980263   \n",
       "1 2023-02-06  Australia           AU  en.wikipedia  28786805   \n",
       "3 2023-02-06  Australia           AU  en.wikipedia     44059   \n",
       "4 2023-02-06  Australia           AU  en.wikipedia     46823   \n",
       "5 2023-02-06  Australia           AU  en.wikipedia     52382   \n",
       "\n",
       "             article       qid  views  \n",
       "0      Margot_Robbie  Q1924847    299  \n",
       "1    Karl_Stefanovic  Q6372275     90  \n",
       "3      Harrison_Ford    Q81328    367  \n",
       "4           George_V   Q269412    125  \n",
       "5  Watergate_scandal    Q42761     97  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script to read DBPD files, and get lines that fit a criteria\n",
    "import pandas as pd\n",
    "import requests, json, datetime, time, io, csv\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def write_to_file(date, entries, saveFile):\n",
    "    \"\"\"Write data to the file, appending each line at the end of file.\n",
    "    It also adds the data in front of the line.\n",
    "    \"\"\"\n",
    "    with open(saveFile, 'a', encoding=\"utf-8\") as outf:\n",
    "        for line, count in entries:\n",
    "            outf.write(f\"{date}\\t{line}\\t{count}\")\n",
    "\n",
    "baseURL = \"https://analytics.wikimedia.org/published/datasets/country_project_page\"\n",
    "startDate1 = \"2023-02-06\"\n",
    "endDate1 = \"2023-12-31\"\n",
    "startDate2 = \"2024-01-01\"\n",
    "endDate2 = \"2024-12-31\"\n",
    "\n",
    "dateRange1 = pd.date_range(start=startDate1,end=endDate1)\n",
    "dateRange2 = pd.date_range(start=startDate2,end=endDate2)\n",
    "\n",
    "saveFile = \"filtered_en_wiki_data.csv\"\n",
    "ourEntries = []\n",
    "\n",
    "for dateRange in [dateRange1, dateRange2]:\n",
    "\n",
    "    for date in dateRange.to_list():\n",
    "        date = str(date.date())\n",
    "\n",
    "        URL = f\"{baseURL}/{date}.tsv\"\n",
    "        #print(URL)\n",
    "\n",
    "        response = requests.get(URL, \n",
    "                                headers={\"User-agent\":\"Wikipedia Bot, student project\"})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = io.StringIO(response.text)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} for date={date}\")\n",
    "            continue\n",
    "\n",
    "        for entry in data:\n",
    "\n",
    "            # Only English Wikipedias\n",
    "            values = entry.strip(\"\\n\").split('\\t')\n",
    "            #print(values)\n",
    "            if values[2].strip() == 'en.wikipedia' and values[0].strip() == 'Australia':\n",
    "                values = [date] + values\n",
    "                ourEntries.append(values)\n",
    "\n",
    "\n",
    "columns = [\"date\", \"country\", \"country_code\", \"project\", \"page_id\", \"article\", \"qid\", \"views\"]\n",
    "df = pd.DataFrame(ourEntries, columns=columns)\n",
    "\n",
    "df[\"views\"] = pd.to_numeric(df[\"views\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "info = df.groupby(\"article\", as_index=False)[\"views\"].sum()\n",
    "\n",
    "top_articles = info.sort_values(\"views\", ascending=False).head(10000)[\"article\"]\n",
    "\n",
    "filtered_df = df[df[\"article\"].isin(top_articles)]\n",
    "\n",
    "filtered_df.to_csv(\"top_australia.csv\", index=False)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d60d5",
   "metadata": {},
   "source": [
    "### India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e7e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>project</th>\n",
       "      <th>page_id</th>\n",
       "      <th>article</th>\n",
       "      <th>qid</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>11353578</td>\n",
       "      <td>Priyanshu_Chatterjee</td>\n",
       "      <td>Q7246522</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>1458025</td>\n",
       "      <td>Satavahana_dynasty</td>\n",
       "      <td>Q5257</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>15719907</td>\n",
       "      <td>Sarath_Babu</td>\n",
       "      <td>Q3595531</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>16709162</td>\n",
       "      <td>Tencent</td>\n",
       "      <td>Q860580</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>17384301</td>\n",
       "      <td>Liver</td>\n",
       "      <td>Q9368</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date country country_code       project   page_id  \\\n",
       "4  2023-02-06   India           IN  en.wikipedia  11353578   \n",
       "9  2023-02-06   India           IN  en.wikipedia   1458025   \n",
       "13 2023-02-06   India           IN  en.wikipedia  15719907   \n",
       "15 2023-02-06   India           IN  en.wikipedia  16709162   \n",
       "18 2023-02-06   India           IN  en.wikipedia  17384301   \n",
       "\n",
       "                 article       qid  views  \n",
       "4   Priyanshu_Chatterjee  Q7246522    129  \n",
       "9     Satavahana_dynasty     Q5257    566  \n",
       "13           Sarath_Babu  Q3595531    304  \n",
       "15               Tencent   Q860580    261  \n",
       "18                 Liver     Q9368    248  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script to read DBPD files, and get lines that fit a criteria\n",
    "import pandas as pd\n",
    "import requests, json, datetime, time, io, csv\n",
    "\n",
    "baseURL = \"https://analytics.wikimedia.org/published/datasets/country_project_page\"\n",
    "startDate1 = \"2023-02-06\"\n",
    "endDate1 = \"2023-12-31\"\n",
    "startDate2 = \"2024-01-01\"\n",
    "endDate2 = \"2024-12-31\"\n",
    "\n",
    "dateRange1 = pd.date_range(start=startDate1,end=endDate1)\n",
    "dateRange2 = pd.date_range(start=startDate2,end=endDate2)\n",
    "\n",
    "saveFile = \"filtered_en_wiki_data.csv\"\n",
    "ourEntries = []\n",
    "\n",
    "for dateRange in [dateRange1, dateRange2]:\n",
    "\n",
    "    for date in dateRange.to_list():\n",
    "        date = str(date.date())\n",
    "\n",
    "        URL = f\"{baseURL}/{date}.tsv\"\n",
    "        #print(URL)\n",
    "\n",
    "        response = requests.get(URL, \n",
    "                                headers={\"User-agent\":\"Wikipedia Bot, student project\"})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = io.StringIO(response.text)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} for date={date}\")\n",
    "            continue\n",
    "\n",
    "        for entry in data:\n",
    "\n",
    "            # Only English Wikipedias\n",
    "            values = entry.strip(\"\\n\").split('\\t')\n",
    "            #print(values)\n",
    "            if values[2].strip() == 'en.wikipedia' and values[0].strip() == 'India':\n",
    "                values = [date] + values\n",
    "                ourEntries.append(values)\n",
    "\n",
    "\n",
    "columns = [\"date\", \"country\", \"country_code\", \"project\", \"page_id\", \"article\", \"qid\", \"views\"]\n",
    "df = pd.DataFrame(ourEntries, columns=columns)\n",
    "\n",
    "df[\"views\"] = pd.to_numeric(df[\"views\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "info = df.groupby(\"article\", as_index=False)[\"views\"].sum()\n",
    "\n",
    "top_articles = info.sort_values(\"views\", ascending=False).head(10000)[\"article\"]\n",
    "\n",
    "filtered_df = df[df[\"article\"].isin(top_articles)]\n",
    "\n",
    "filtered_df.to_csv(\"top_india.csv\", index=False)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0cbd5",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef42aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>project</th>\n",
       "      <th>page_id</th>\n",
       "      <th>article</th>\n",
       "      <th>qid</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>16422</td>\n",
       "      <td>Joni_Mitchell</td>\n",
       "      <td>Q205721</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>170388</td>\n",
       "      <td>Ash_Wednesday</td>\n",
       "      <td>Q123542</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>18717177</td>\n",
       "      <td>Shrek</td>\n",
       "      <td>Q483815</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>1923870</td>\n",
       "      <td>The_Pirate_Bay</td>\n",
       "      <td>Q22663</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>2099821</td>\n",
       "      <td>Dallas_Green_(musician)</td>\n",
       "      <td>Q1094052</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date country country_code       project   page_id  \\\n",
       "3 2023-02-06  Canada           CA  en.wikipedia     16422   \n",
       "4 2023-02-06  Canada           CA  en.wikipedia    170388   \n",
       "7 2023-02-06  Canada           CA  en.wikipedia  18717177   \n",
       "8 2023-02-06  Canada           CA  en.wikipedia   1923870   \n",
       "9 2023-02-06  Canada           CA  en.wikipedia   2099821   \n",
       "\n",
       "                   article       qid  views  \n",
       "3            Joni_Mitchell   Q205721    174  \n",
       "4            Ash_Wednesday   Q123542    102  \n",
       "7                    Shrek   Q483815    138  \n",
       "8           The_Pirate_Bay    Q22663    434  \n",
       "9  Dallas_Green_(musician)  Q1094052    151  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script to read DBPD files, and get lines that fit a criteria\n",
    "import pandas as pd\n",
    "import requests, json, datetime, time, io, csv\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def write_to_file(date, entries, saveFile):\n",
    "    \"\"\"Write data to the file, appending each line at the end of file.\n",
    "    It also adds the data in front of the line.\n",
    "    \"\"\"\n",
    "    with open(saveFile, 'a', encoding=\"utf-8\") as outf:\n",
    "        for line, count in entries:\n",
    "            outf.write(f\"{date}\\t{line}\\t{count}\")\n",
    "\n",
    "baseURL = \"https://analytics.wikimedia.org/published/datasets/country_project_page\"\n",
    "startDate1 = \"2023-02-06\"\n",
    "endDate1 = \"2023-12-31\"\n",
    "startDate2 = \"2024-01-01\"\n",
    "endDate2 = \"2024-12-31\"\n",
    "\n",
    "dateRange1 = pd.date_range(start=startDate1,end=endDate1)\n",
    "dateRange2 = pd.date_range(start=startDate2,end=endDate2)\n",
    "\n",
    "saveFile = \"filtered_en_wiki_data.csv\"\n",
    "ourEntries = []\n",
    "\n",
    "for dateRange in [dateRange1, dateRange2]:\n",
    "\n",
    "    for date in dateRange.to_list():\n",
    "        date = str(date.date())\n",
    "\n",
    "        URL = f\"{baseURL}/{date}.tsv\"\n",
    "        #print(URL)\n",
    "\n",
    "        response = requests.get(URL, \n",
    "                                headers={\"User-agent\":\"Wikipedia Bot, student project\"})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = io.StringIO(response.text)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} for date={date}\")\n",
    "            continue\n",
    "\n",
    "        for entry in data:\n",
    "\n",
    "            # Only English Wikipedias\n",
    "            values = entry.strip(\"\\n\").split('\\t')\n",
    "            #print(values)\n",
    "            if values[2].strip() == 'en.wikipedia' and values[0].strip() == 'Canada':\n",
    "                values = [date] + values\n",
    "                ourEntries.append(values)\n",
    "\n",
    "\n",
    "columns = [\"date\", \"country\", \"country_code\", \"project\", \"page_id\", \"article\", \"qid\", \"views\"]\n",
    "df = pd.DataFrame(ourEntries, columns=columns)\n",
    "\n",
    "df[\"views\"] = pd.to_numeric(df[\"views\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "info = df.groupby(\"article\", as_index=False)[\"views\"].sum()\n",
    "\n",
    "top_articles = info.sort_values(\"views\", ascending=False).head(10000)[\"article\"]\n",
    "\n",
    "filtered_df = df[df[\"article\"].isin(top_articles)]\n",
    "\n",
    "filtered_df.to_csv(\"top_canada.csv\", index=False)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff11995",
   "metadata": {},
   "source": [
    "### United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6ee20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>project</th>\n",
       "      <th>page_id</th>\n",
       "      <th>article</th>\n",
       "      <th>qid</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>11061916</td>\n",
       "      <td>Calvin_Johnson</td>\n",
       "      <td>Q857634</td>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>1224736</td>\n",
       "      <td>John_Drew_Barrymore</td>\n",
       "      <td>Q962932</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>127062</td>\n",
       "      <td>Staten_Island</td>\n",
       "      <td>Q18432</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>13815</td>\n",
       "      <td>Heracles</td>\n",
       "      <td>Q122248</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>159362</td>\n",
       "      <td>John_F._Kennedy_Jr.</td>\n",
       "      <td>Q316064</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        country country_code       project   page_id  \\\n",
       "7  2023-02-06  United States           US  en.wikipedia  11061916   \n",
       "11 2023-02-06  United States           US  en.wikipedia   1224736   \n",
       "12 2023-02-06  United States           US  en.wikipedia    127062   \n",
       "16 2023-02-06  United States           US  en.wikipedia     13815   \n",
       "24 2023-02-06  United States           US  en.wikipedia    159362   \n",
       "\n",
       "                article      qid  views  \n",
       "7        Calvin_Johnson  Q857634   1449  \n",
       "11  John_Drew_Barrymore  Q962932   1263  \n",
       "12        Staten_Island   Q18432   1313  \n",
       "16             Heracles  Q122248   1655  \n",
       "24  John_F._Kennedy_Jr.  Q316064   3003  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script to read DBPD files, and get lines that fit a criteria\n",
    "import pandas as pd\n",
    "import requests, json, datetime, time, io, csv\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def write_to_file(date, entries, saveFile):\n",
    "    \"\"\"Write data to the file, appending each line at the end of file.\n",
    "    It also adds the data in front of the line.\n",
    "    \"\"\"\n",
    "    with open(saveFile, 'a', encoding=\"utf-8\") as outf:\n",
    "        for line, count in entries:\n",
    "            outf.write(f\"{date}\\t{line}\\t{count}\")\n",
    "\n",
    "baseURL = \"https://analytics.wikimedia.org/published/datasets/country_project_page\"\n",
    "startDate1 = \"2023-02-06\"\n",
    "endDate1 = \"2023-12-31\"\n",
    "startDate2 = \"2024-01-01\"\n",
    "endDate2 = \"2024-12-31\"\n",
    "\n",
    "dateRange1 = pd.date_range(start=startDate1,end=endDate1)\n",
    "dateRange2 = pd.date_range(start=startDate2,end=endDate2)\n",
    "\n",
    "saveFile = \"filtered_en_wiki_data.csv\"\n",
    "ourEntries = []\n",
    "\n",
    "for dateRange in [dateRange1, dateRange2]:\n",
    "\n",
    "    for date in dateRange.to_list():\n",
    "        date = str(date.date())\n",
    "\n",
    "        URL = f\"{baseURL}/{date}.tsv\"\n",
    "        #print(URL)\n",
    "\n",
    "        response = requests.get(URL, \n",
    "                                headers={\"User-agent\":\"Wikipedia Bot, student project\"})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = io.StringIO(response.text)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} for date={date}\")\n",
    "            continue\n",
    "\n",
    "        for entry in data:\n",
    "\n",
    "            # Only English Wikipedias\n",
    "            values = entry.strip(\"\\n\").split('\\t')\n",
    "            #print(values)\n",
    "            if values[2].strip() == 'en.wikipedia' and values[0].strip() == 'United States':\n",
    "                values = [date] + values\n",
    "                ourEntries.append(values)\n",
    "\n",
    "\n",
    "columns = [\"date\", \"country\", \"country_code\", \"project\", \"page_id\", \"article\", \"qid\", \"views\"]\n",
    "df = pd.DataFrame(ourEntries, columns=columns)\n",
    "\n",
    "df[\"views\"] = pd.to_numeric(df[\"views\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "info = df.groupby(\"article\", as_index=False)[\"views\"].sum()\n",
    "\n",
    "top_articles = info.sort_values(\"views\", ascending=False).head(10000)[\"article\"]\n",
    "\n",
    "filtered_df = df[df[\"article\"].isin(top_articles)]\n",
    "\n",
    "filtered_df.to_csv(\"top_united_states.csv\", index=False)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a4f3e",
   "metadata": {},
   "source": [
    "### United Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8297c7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>project</th>\n",
       "      <th>page_id</th>\n",
       "      <th>article</th>\n",
       "      <th>qid</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>102994</td>\n",
       "      <td>Bill_Murray</td>\n",
       "      <td>Q29250</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>10577056</td>\n",
       "      <td>Ashes_to_Ashes_(British_TV_series)</td>\n",
       "      <td>Q725195</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>11500785</td>\n",
       "      <td>Red_Dead_Redemption</td>\n",
       "      <td>Q548203</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>12577850</td>\n",
       "      <td>Victor_Moses</td>\n",
       "      <td>Q295637</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>149612</td>\n",
       "      <td>Sertraline</td>\n",
       "      <td>Q407617</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         country country_code       project   page_id  \\\n",
       "0  2023-02-06  United Kingdom           GB  en.wikipedia    102994   \n",
       "1  2023-02-06  United Kingdom           GB  en.wikipedia  10577056   \n",
       "3  2023-02-06  United Kingdom           GB  en.wikipedia  11500785   \n",
       "7  2023-02-06  United Kingdom           GB  en.wikipedia  12577850   \n",
       "12 2023-02-06  United Kingdom           GB  en.wikipedia    149612   \n",
       "\n",
       "                               article      qid  views  \n",
       "0                          Bill_Murray   Q29250    310  \n",
       "1   Ashes_to_Ashes_(British_TV_series)  Q725195    197  \n",
       "3                  Red_Dead_Redemption  Q548203    159  \n",
       "7                         Victor_Moses  Q295637    170  \n",
       "12                          Sertraline  Q407617    482  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script to read DBPD files, and get lines that fit a criteria\n",
    "import pandas as pd\n",
    "import requests, json, datetime, time, io, csv\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def write_to_file(date, entries, saveFile):\n",
    "    \"\"\"Write data to the file, appending each line at the end of file.\n",
    "    It also adds the data in front of the line.\n",
    "    \"\"\"\n",
    "    with open(saveFile, 'a', encoding=\"utf-8\") as outf:\n",
    "        for line, count in entries:\n",
    "            outf.write(f\"{date}\\t{line}\\t{count}\")\n",
    "\n",
    "baseURL = \"https://analytics.wikimedia.org/published/datasets/country_project_page\"\n",
    "startDate1 = \"2023-02-06\"\n",
    "endDate1 = \"2023-12-31\"\n",
    "startDate2 = \"2024-01-01\"\n",
    "endDate2 = \"2024-12-31\"\n",
    "\n",
    "dateRange1 = pd.date_range(start=startDate1,end=endDate1)\n",
    "dateRange2 = pd.date_range(start=startDate2,end=endDate2)\n",
    "\n",
    "saveFile = \"filtered_en_wiki_data.csv\"\n",
    "ourEntries = []\n",
    "\n",
    "for dateRange in [dateRange1, dateRange2]:\n",
    "\n",
    "    for date in dateRange.to_list():\n",
    "        date = str(date.date())\n",
    "\n",
    "        URL = f\"{baseURL}/{date}.tsv\"\n",
    "        #print(URL)\n",
    "\n",
    "        response = requests.get(URL, \n",
    "                                headers={\"User-agent\":\"Wikipedia Bot, student project\"})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = io.StringIO(response.text)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} for date={date}\")\n",
    "            continue\n",
    "\n",
    "        for entry in data:\n",
    "\n",
    "            # Only English Wikipedias\n",
    "            values = entry.strip(\"\\n\").split('\\t')\n",
    "            #print(values)\n",
    "            if values[2].strip() == 'en.wikipedia' and values[0].strip() == 'United Kingdom':\n",
    "                values = [date] + values\n",
    "                ourEntries.append(values)\n",
    "\n",
    "\n",
    "columns = [\"date\", \"country\", \"country_code\", \"project\", \"page_id\", \"article\", \"qid\", \"views\"]\n",
    "df = pd.DataFrame(ourEntries, columns=columns)\n",
    "\n",
    "df[\"views\"] = pd.to_numeric(df[\"views\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "info = df.groupby(\"article\", as_index=False)[\"views\"].sum()\n",
    "\n",
    "top_articles = info.sort_values(\"views\", ascending=False).head(10000)[\"article\"]\n",
    "\n",
    "filtered_df = df[df[\"article\"].isin(top_articles)]\n",
    "\n",
    "filtered_df.to_csv(\"top_uk.csv\", index=False)\n",
    "filtered_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
